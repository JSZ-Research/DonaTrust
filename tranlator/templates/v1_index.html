<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>AI Sign Language Translator</title>
    <script src="https://cdn.socket.io/4.0.0/socket.io.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; display: flex; background: #121212; color: #e0e0e0; margin: 0; }
        .container { display: flex; width: 100vw; height: 100vh; }
        
        .video-box { position: relative; flex: 3; background: #000; overflow: hidden; }
        #webcam { width: 100%; height: 100%; object-fit: cover; transform: rotateY(180deg); }
        #output_canvas { position: absolute; top:0; left:0; width: 100%; height: 100%; transform: rotateY(180deg); }
        
        .sidebar { flex: 1; padding: 30px; border-left: 1px solid #333; display: flex; flex-direction: column; gap: 20px; background: #1e1e1e; }
        .result-card { background: #2d2d2d; padding: 25px; border-radius: 15px; text-align: center; box-shadow: 0 4px 15px rgba(0,0,0,0.3); }
        #status-text { font-size: 48px; font-weight: bold; color: #4CAF50; margin: 10px 0; }
        #dist-info { color: #888; font-family: monospace; }
        
        .controls { display: flex; flex-direction: column; gap: 10px; }
        button { padding: 15px; border-radius: 8px; border: none; background: #007bff; color: white; font-weight: bold; cursor: pointer; transition: 0.3s; }
        button:hover { background: #0056b3; }
        button.secondary { background: #444; }
        .hint { font-size: 12px; color: #666; margin-top: 10px; }
    </style>
</head>
<body>
    <div class="container">
        <div class="video-box">
            <video id="webcam"></video>
            <canvas id="output_canvas"></canvas>
        </div>
        <div class="sidebar">
            <div class="result-card">
                <h3>Translation</h3>
                <div id="status-text">Ready</div>
                <div id="dist-info">Distance: -</div>
            </div>
            
            <div class="controls">
                <h4>Training Panel</h4>
                <button onclick="record('Hello')">Record "Hello"</button>
                <button onclick="record('Thank you')">Record "Thank you"</button>
                <p class="hint">Perform the gesture, then click the button to save.</p>
            </div>
        </div>
    </div>

<script>
    const socket = io();
    const videoElement = document.getElementById('webcam');
    const canvasElement = document.getElementById('output_canvas');
    const canvasCtx = canvasElement.getContext('2d');
    let lastFeatures = null;

    // Feature normalization logic
    function normalize(landmarks) {
        let xs = landmarks.map(l => l.x);
        let ys = landmarks.map(l => l.y);
        let centerX = xs.reduce((a,b)=>a+b)/21;
        let centerY = ys.reduce((a,b)=>a+b)/21;
        
        let points = landmarks.map(l => [l.x - centerX, l.y - centerY]);
        let maxDist = Math.max(...points.map(p => Math.sqrt(p[0]**2 + p[1]**2)));
        
        return points.map(p => [p[0]/maxDist, p[1]/maxDist]).flat();
    }

    function onResults(results) {
        canvasCtx.save();
        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
            const lms = results.multiHandLandmarks[0];
            // Draw visual skeleton
            drawConnectors(canvasCtx, lms, HAND_CONNECTIONS, {color: '#00FF00', lineWidth: 4});
            drawLandmarks(canvasCtx, lms, {color: '#FF0000', lineWidth: 1, radius: 2});
            
            lastFeatures = normalize(lms);
            // Send normalized coordinates to Flask
            socket.emit('process_frame', {features: lastFeatures});
        } else {
            document.getElementById('status-text').innerText = "No Hand";
        }
        canvasCtx.restore();
    }

    const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.7});
    hands.onResults(onResults);

    const camera = new Camera(videoElement, {
        onFrame: async () => { await hands.send({image: videoElement}); },
        width: 1280, height: 720
    });
    camera.start();

    // Listen for translation results from backend
    socket.on('response_result', (data) => {
        const textElem = document.getElementById('status-text');
        textElem.innerText = data.best_match;
        textElem.style.color = data.best_match === "Unknown" ? "#ff4444" : "#4CAF50";
        document.getElementById('dist-info').innerText = "Confidence Dist: " + data.dist;
    });

    function record(gestureName) {
        if (lastFeatures) {
            socket.emit('record_gesture', {name: gestureName, features: lastFeatures});
        } else {
            alert("No hand detected! Please show your hand to the camera.");
        }
    }

    socket.on('record_status', (data) => alert("Successfully recorded: " + data.name));
</script>
</body>
</html>
